<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>HandPose</title>
</head>
<body>
  <script src="https://unpkg.com/ml5@1/dist/ml5.js"></script>
  <script>

    let video, canvas, ctx;
    let handPose;
    let hands = [];

    const preload = async () => {
      console.log('preload');
      handPose = ml5.handPose();
      await handPose.ready;
      console.log('model ready');
      setup();
    }

    const setup = async () => {
      console.log('setup');
      // create a canvas
      canvas = document.createElement('canvas');
      document.body.appendChild(canvas);
      ctx = canvas.getContext('2d');
      // create a video stream - specify a fixed size
      const stream = await navigator.mediaDevices.getUserMedia({ video: {
        width: 640,
        height: 480
      } });
      video = document.createElement('video');
      video.srcObject = stream;
      video.play();
      // set canvas & video size
      canvas.width = video.width = 640;
      canvas.height = video.height = 480;
      // start detecting poses - use the canvas instead of the video (BlazePose compatibility)
      handPose.detectStart(video, gotPoses);
      requestAnimationFrame(draw);
    }

    const gotPoses = (results) => {
      hands = results;
    }

    const draw = () => {
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
      ctx.fillStyle = 'red';
      hands.forEach(hand => {
        hand.keypoints.forEach(keypoint => {
          // no confidence score for handPose
          ctx.beginPath();
          ctx.arc(keypoint.x, keypoint.y, 10, 0, 2 * Math.PI);
          ctx.fill();
        });
      });
      requestAnimationFrame(draw);
    }

    preload();
  </script>
</body>
</html>