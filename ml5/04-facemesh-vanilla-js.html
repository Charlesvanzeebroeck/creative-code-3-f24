<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Facemesh</title>
</head>
<body>
  <script src="https://unpkg.com/ml5@1/dist/ml5.js"></script>
  <script>

    let video, canvas, ctx;
    let faceMesh;
    let options = { maxFaces: 1, refineLandmarks: false, flipped: false };
    let faces = [];

    async function preload() {
      console.log('preload');
      faceMesh = ml5.faceMesh(options);
      await faceMesh.ready;
      console.log('model ready');
      setup();
    }

    async function setup() {
      console.log('setup');
      // create a canvas
      canvas = document.createElement('canvas');
      document.body.appendChild(canvas);
      ctx = canvas.getContext('2d');
      // create a video stream - specify a fixed size
      const stream = await navigator.mediaDevices.getUserMedia({ video: {
        width: 640,
        height: 480
      } });
      video = document.createElement('video');
      video.srcObject = stream;
      video.play();
      // set canvas & video size
      canvas.width = video.width = 640;
      canvas.height = video.height = 480;
      // start detecting poses - use the canvas instead of the video (BlazePose compatibility)
      faceMesh.detectStart(video, gotPoses);
      requestAnimationFrame(draw);
    }

    function gotPoses(results) {
      faces = results;
    }

    function draw() {
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
      ctx.fillStyle = 'red';
      faces.forEach(face => {
        face.keypoints.forEach(keypoint => {
          ctx.beginPath();
          ctx.arc(keypoint.x, keypoint.y, 4, 0, 2 * Math.PI);
          ctx.fill();
        });
      });
      requestAnimationFrame(draw);
    }

    preload();
  </script>
</body>
</html>